# Evaluation-of-Optimization-Algorithms-on-LeNet5-for-MNIST-Data
ABSTRACT
Optimization Algorithms play a crucial role in improving a deep learning model’s performance. They affect the accuracy and training time of the deep learning model. Optimizers are used to adjust the models’ parameters such as weights to reduce the overall loss and improve accuracy. In this project, I evaluate the performance of three optimizers, Stochastic Gradient Descent (SGD), Adaptive Gradient Optimizer (Adagrad), and Root Mean Squared Propagation (RMSprop), on a LeNet 5 network using MNIST data.
